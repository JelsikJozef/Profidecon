# Profidecon - HybridnÃ½ RAG systÃ©m pre prÃ¡vne dokumenty

Profidecon je pokroÄilÃ½ systÃ©m pre spracovanie a vyhÄ¾adÃ¡vanie prÃ¡vnych dokumentov pouÅ¾Ã­vajÃºci hybridnÃ© vyhÄ¾adÃ¡vanie s dual vectors a tag boosting pre optimÃ¡lne vÃ½sledky.

## ğŸš€ KÄ¾ÃºÄovÃ© funkcie

- **HybridnÃ© vyhÄ¾adÃ¡vanie**: Dual vector embeddings (text + summary) s tag-based score boosting
- **PokroÄilÃ© spracovanie**: OCR, normalizÃ¡cia textu, deduplication a kvalitnÃ© kontroly
- **TaxonÃ³mia dokumentov**: AutomatickÃ¡ kategorizÃ¡cia a extraktion tagov pomocou LLM
- **RAG optimalizÃ¡cia**: OptimalizovanÃ© pre slovenÄinu a prÃ¡vne dokumenty
- **VysokÃ¡ presnosÅ¥**: 67% Recall@10 na testovacÃ­ch dÃ¡tach

## ğŸ“¦ InÅ¡talÃ¡cia

```bash
# Klonovanie repozitÃ¡ra
git clone <repository-url>
cd Profidecon

# InÅ¡talÃ¡cia zÃ¡vislostÃ­
pip install -e .

# Spustenie Qdrant servera
docker run -p 6333:6333 qdrant/qdrant
```

## ğŸ› ï¸ PouÅ¾itie

### CLI nÃ¡stroj
Po inÅ¡talÃ¡cii mÃ¡te k dispozÃ­cii `profidecon` CLI:

```bash
profidecon --help
```

## ğŸ“‹ PrÃ­klad workflow

### 1. Spracovanie dokumentov
```bash
# Spracovanie dokumentov s OCR a normalizÃ¡ciou
profidecon preprocess --input ./Knowledge --output ./Preprocessed
```

### 2. Vytvorenie taxonÃ³mie
```bash
# AnalÃ½za a vytvorenie taxonÃ³mie zo vÅ¡etkÃ½ch JSONL sÃºborov
profidecon taxonomy-analyze --input ./Preprocessed --output ./Taxonomy
```

### 3. NaÄÃ­tanie dual vectors do Qdrant
```bash
# Vytvorenie embeddings pre text aj summary s dual vector support
profidecon vector-load ./Preprocessed --glob "*.jsonl"
```

### 4. HybridnÃ© vyhÄ¾adÃ¡vanie

```python
from sdk.retrieval import RetrievalEngine

# InicializÃ¡cia retrieval engine
engine = RetrievalEngine()

# HybridnÃ© vyhÄ¾adÃ¡vanie s tag boostingom
results = engine.search(
    query="poplatok na ambasÃ¡de",
    user_tags=["poplatok", "prechodnÃ½ pobyt"],
    tag_boost=0.25,  # 25% boost pre matching tagy
    limit=10
)

# Zobrazenie vÃ½sledkov
for i, result in enumerate(results, 1):
    boost_indicator = "ğŸ“ˆ BOOSTED" if result.was_boosted else ""
    print(f"{i}. {boost_indicator} Score: {result.score:.3f}")
    print(f"   Category: {result.category}")
    print(f"   Text: {result.text[:100]}...")
    if result.matched_tags:
        print(f"   ğŸ¯ Matched tags: {result.matched_tags}")
```

### 5. Summary Vector Search
```python
# VyhÄ¾adÃ¡vanie v summary embeddings
summary_results = engine.search_summary_vector(
    query="dokumenty potrebnÃ© pre pobyt",
    user_tags=["dokumenty", "pobyt"],
    limit=5
)
```

## ğŸ¯ HybridnÃ© vyhÄ¾adÃ¡vanie funkcie

### Dual Vector Embeddings
- **Body vectors**: Embeddings plnÃ©ho textu dokumentu
- **Summary vectors**: Embeddings sÃºhrnu dokumentu
- MoÅ¾nosÅ¥ vyhÄ¾adÃ¡vania v oboch typoch vektorov

### Tag Boosting
- AutomatickÃ© zvÃ½Å¡enie skÃ³re dokumentov s matching tagmi
- KonfigurovateÄ¾nÃ½ boost factor (default 20%)
- InteligentnÃ¡ re-ranking vÃ½sledkov

### KonfigurÃ¡cia vyhÄ¾adÃ¡vania
```python
from vectorizer.settings import settings

# Ãšprava globÃ¡lnych nastavenÃ­
settings.tag_boost = 0.30        # 30% boost
settings.search_limit = 15       # 15 vÃ½sledkov
settings.use_summary_vector = True  # PouÅ¾iÅ¥ summary vektor
```

## ğŸ“Š VÃ½konnosÅ¥ systÃ©mu

Na testovacÃ­ch dÃ¡tach (33 ground truth queries):
- **Recall@10: 66.7%** (22/33 sprÃ¡vnych vÃ½sledkov)
- **Tag boost efektÃ­vnosÅ¥: 36.4%** dotazov profituje z boostingu
- **Dual vector podpora**: Seamless switching medzi text a summary embeddings

## ğŸ—‚ï¸ Å truktÃºra projektu

```
Profidecon/
â”œâ”€â”€ preprocessor/        # Document processing pipeline
â”‚   â”œâ”€â”€ taxonomy/       # LLM-based taxonomy extraction
â”‚   â””â”€â”€ processors/     # OCR, normalization, quality checks
â”œâ”€â”€ vectorizer/         # Dual vector embedding system  
â”‚   â”œâ”€â”€ embedder.py    # SentenceTransformer wrapper
â”‚   â”œâ”€â”€ loader.py      # Qdrant integration with dual vectors
â”‚   â””â”€â”€ settings.py    # Configuration management
â”œâ”€â”€ sdk/               # Retrieval API
â”‚   â””â”€â”€ retrieval.py   # Hybrid search engine
â”œâ”€â”€ tests/             # Test data and evaluation
â””â”€â”€ profidecon/        # Main CLI application
```

## ğŸ“š DokumentÃ¡cia API

### RetrievalEngine

```python
from sdk.retrieval import RetrievalEngine

engine = RetrievalEngine()

# ZÃ¡kladnÃ© vyhÄ¾adÃ¡vanie
results = engine.search(query="text", user_tags=["tag1", "tag2"])

# PokroÄilÃ© moÅ¾nosti
results = engine.search(
    query="search text",
    user_tags=["tag1", "tag2"],
    limit=10,
    tag_boost=0.25,
    use_summary_vector=False
)

# Summary vector search
results = engine.search_summary_vector(query="text", user_tags=["tag"])

# ZÃ­skanie dokumentu podÄ¾a ID  
doc = engine.get_document_by_id("document-uuid")

# Å tatistiky kolekcie
stats = engine.get_collection_stats()
```

### SearchResult Object

```python
@dataclass
class SearchResult:
    id: str                    # Document UUID
    score: float              # Final score (potentially boosted)
    original_score: float     # Original vector similarity score
    text: str                 # Full document text
    summary: str              # Document summary
    tags: List[str]           # Document tags
    category: str             # Document category
    source: str               # Original file path
    was_boosted: bool         # Whether tag boosting was applied
    boost_factor: float       # Applied boost factor
    matched_tags: List[str]   # Tags that matched user query
```

## âš™ï¸ KonfigurÃ¡cia

SystÃ©m pouÅ¾Ã­va `vectorizer/settings.py` pre konfigurÃ¡ciu:

```python
# Embedding model
embed_model = "intfloat/multilingual-e5-base"

# Qdrant nastavenia  
qdrant_url = "http://localhost:6333"
qdrant_collection = "profidecon_docs"

# VyhÄ¾adÃ¡vanie
tag_boost = 0.20              # 20% boost pre matching tagy
search_limit = 10             # PoÄet vÃ½sledkov
use_summary_vector = False    # Typ vektora pre vyhÄ¾adÃ¡vanie

# Processing
batch_size = 32
chunk_size = 450
chunk_overlap = 100
```

## ğŸ§ª Testovanie

```bash
# Test hybridnÃ©ho vyhÄ¾adÃ¡vania
python test_hybrid_search.py

# EvaluÃ¡cia na ground truth dÃ¡tach
python test_human_csv.py

# RAG pipeline evaluÃ¡cia
python evaluate_rag.py
```

## ğŸ“ˆ Metriky kvality

SystÃ©m poskytuje kompletnÃº evaluÃ¡ciu:
- **Recall@K**: ÃšspeÅ¡nosÅ¥ nÃ¡jdenia sprÃ¡vnych dokumentov
- **Tag boost impact**: EfektÃ­vnosÅ¥ tag boostingu
- **Vector type comparison**: Body vs summary embeddings
- **Response time**: RÃ½chlosÅ¥ vyhÄ¾adÃ¡vania

## ğŸ”§ PokroÄilÃ© pouÅ¾itie

### Custom embedding models
```python
from vectorizer.settings import Settings

settings = Settings(embed_model="your-custom-model")
engine = RetrievalEngine(settings)
```

### Batch processing
```python
# Spracovanie viacerÃ½ch dotazov
queries = ["query1", "query2", "query3"]
all_results = []

for query in queries:
    results = engine.search(query, tag_boost=0.30)
    all_results.extend(results)
```

## ğŸ› RieÅ¡enie problÃ©mov

### Qdrant connection issues
```bash
# Skontrolujte Äi beÅ¾Ã­ Qdrant server
curl http://localhost:6333/collections

# ReÅ¡tart Qdrant
docker restart qdrant-container
```

### Embedding model loading
```bash
# Pre offline pouÅ¾itie, predownloadujte model
python -c "from sentence_transformers import SentenceTransformer; SentenceTransformer('intfloat/multilingual-e5-base')"
```

## ğŸ¤ Prispievanie

1. Fork repozitÃ¡ra
2. Vytvorte feature branch (`git checkout -b feature/amazing-feature`)
3. Commit zmeny (`git commit -m 'Add amazing feature'`)
4. Push branch (`git push origin feature/amazing-feature`)
5. Otvorte Pull Request

## ğŸ“„ Licencia

MIT

## ğŸ“ Kontakt

V prÃ­pade otÃ¡zok kontaktujte autora projektu.
